import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Download the 'punkt' resource
nltk.download('punkt')

nltk.download('stopwords')

def preprocess_text(text):
    # Tokenize the text into sentences and words
    sentences = sent_tokenize(text)
    words = [word.lower() for sentence in sentences for word in word_tokenize(sentence) if word.isalnum()]

    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]

    return sentences, words

def calculate_coherence(text):
    sentences, words = preprocess_text(text)

    # Create a TF-IDF vectorizer
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(sentences)

    # Calculate pairwise cosine similarity between sentences
    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

    # Calculate coherence score as the average similarity between sentences
    coherence_score = similarity_matrix.mean()

    return coherence_score

if __name__ == "__main__":
    # Example usage
    input_text = "Natural language processing is a subfield of artificial intelligence. It focuses on the interaction between computers and humans using natural language. Coherence in text is important for effective communication."

    # Calculate coherence score
    coherence_score = calculate_coherence(input_text)

    # Display the result
    print(f"Coherence Score: {coherence_score}")
